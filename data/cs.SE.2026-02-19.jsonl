{"id": "http://arxiv.org/abs/2602.17640v1", "title": "huff: A Python package for Market Area Analysis", "summary": "Market area models, such as the Huff model and its extensions, are widely used to estimate regional market shares and customer flows of retail and service locations. Another, now very common, area of application is the analysis of catchment areas, supply structures and the accessibility of healthcare locations. The huff Python package provides a complete workflow for market area analysis, including data import, construction of origin-destination interaction matrices, basic model analysis, parameter estimation from empirical data, calculation of distance or travel time indicators, and map visualization. Additionally, the package provides several methods of spatial accessibility analysis. The package is modular and object-oriented. It is intended for researchers in economic geography, regional economics, spatial planning, marketing, geoinformation science, and health geography. The software is openly available via the [Python Package Index (PyPI)](https://pypi.org/project/huff/); its development and version history are managed in a public [GitHub Repository](https://github.com/geowieland/huff_official) and archived at [Zenodo](https://doi.org/10.5281/zenodo.18639559).", "published": "2026-02-19T18:52:46Z", "updated": "2026-02-19T18:52:46Z", "authors": ["Thomas Wieland"], "pdf_url": "https://arxiv.org/pdf/2602.17640v1"}
{"id": "http://arxiv.org/abs/2602.17622v1", "title": "What Makes a Good LLM Agent for Real-world Penetration Testing?", "summary": "LLM-based agents show promise for automating penetration testing, yet reported performance varies widely across systems and benchmarks. We analyze 28 LLM-based penetration testing systems and evaluate five representative implementations across three benchmarks of increasing complexity. Our analysis reveals two distinct failure modes: Type A failures stem from capability gaps (missing tools, inadequate prompts) that engineering readily addresses, while Type B failures persist regardless of tooling due to planning and state management limitations. We show that Type B failures share a root cause that is largely invariant to the underlying LLM: agents lack real-time task difficulty estimation. As a result, agents misallocate effort, over-commit to low-value branches, and exhaust context before completing attack chains.\n  Based on this insight, we present Excalibur, a penetration testing agent that couples strong tooling with difficulty-aware planning. A Tool and Skill Layer eliminates Type A failures through typed interfaces and retrieval-augmented knowledge. A Task Difficulty Assessment (TDA) mechanism addresses Type B failures by estimating tractability through four measurable dimensions (horizon estimation, evidence confidence, context load, and historical success) and uses these estimates to guide exploration-exploitation decisions within an Evidence-Guided Attack Tree Search (EGATS) framework. Excalibur achieves up to 91% task completion on CTF benchmarks with frontier models (39 to 49% relative improvement over baselines) and compromises 4 of 5 hosts on the GOAD Active Directory environment versus 2 by prior systems. These results show that difficulty-aware planning yields consistent end-to-end gains across models and addresses a limitation that model scaling alone does not eliminate.", "published": "2026-02-19T18:42:40Z", "updated": "2026-02-19T18:42:40Z", "authors": ["Gelei Deng", "Yi Liu", "Yuekang Li", "Ruozhao Yang", "Xiaofei Xie", "Jie Zhang", "Han Qiu", "Tianwei Zhang"], "pdf_url": "https://arxiv.org/pdf/2602.17622v1"}
{"id": "http://arxiv.org/abs/2602.17498v1", "title": "Towards a Software Reference Architecture for Natural Language Processing Tools in Requirements Engineering", "summary": "Natural Language Processing (NLP) tools support requirements engineering (RE) tasks like requirements elicitation, classification, and validation. However, they are often developed from scratch despite functional overlaps, and abandoned after publication. This lack of interoperability and maintenance incurs unnecessary development effort, impedes tool comparison and benchmarking, complicates documentation, and diminishes the long-term sustainability of NLP4RE tools. To address these issues, we postulate a vision to transition from monolithic NLP4RE tools to an ecosystem of reusable, interoperable modules. We outline a research roadmap towards a software reference architecture (SRA) to realize this vision, elaborated following a standard methodological framework for SRA development. As an initial step, we conducted a stakeholder-driven focus group session to elicit generic system requirements for NLP4RE tools. This activity resulted in 36 key system requirements, further motivating the need for a dedicated SRA. Overall, the proposed vision, roadmap, and initial contribution pave the way towards improved development, reuse, and long-term maintenance of NLP4RE tools.", "published": "2026-02-19T16:14:22Z", "updated": "2026-02-19T16:14:22Z", "authors": ["Julian Frattini", "Quim Motger"], "pdf_url": "https://arxiv.org/pdf/2602.17498v1"}
{"id": "http://arxiv.org/abs/2602.08801v2", "title": "Verifying DNN-based Semantic Communication Against Generative Adversarial Noise", "summary": "Safety-critical applications like autonomous vehicles and industrial IoT are adopting semantic communication (SemCom) systems using deep neural networks to reduce bandwidth and increase transmission speed by transmitting only task-relevant semantic features.\n  However, adversarial attacks against these DNN-based SemCom systems can cause catastrophic failures by manipulating transmitted semantic features.\n  Existing defense mechanisms rely on empirical approaches provide no formal guarantees against the full spectrum of adversarial perturbations.\n  We present VSCAN, a neural network verification framework that provides mathematical robustness guarantees by formulating adversarial noise generation as mixed integer programming and verifying end-to-end properties across multiple interconnected networks (encoder, decoder, and task model).\n  Our key insight is that realistic adversarial constraints (power limitations and statistical undetectability) can be encoded as logical formulae to enable efficient verification using state-of-the-art DNN verifiers.\n  Our evaluation on 600 verification properties characterizing various attacker's capabilities shows VSCAN matches attack methods in finding vulnerabilities while providing formal robustness guarantees for 44% of properties -- a significant achievement given the complexity of multi-network verification.\n  Moreover, we reveal a fundamental security-efficiency tradeoff: compact 16-dimensional latent spaces achieve 50% verified robustness compared to 64-dimensional spaces.", "published": "2026-02-09T15:40:13Z", "updated": "2026-02-19T15:53:59Z", "authors": ["Thanh Le", "Hai Duong", "ThanhVu Nguyen", "Takeshi Matsumura"], "pdf_url": "https://arxiv.org/pdf/2602.08801v2"}
{"id": "http://arxiv.org/abs/2602.17426v1", "title": "The Runtime Dimension of Ethics in Self-Adaptive Systems", "summary": "Self-adaptive systems increasingly operate in close interaction with humans, often sharing the same physical or virtual environments and making decisions with ethical implications at runtime. Current approaches typically encode ethics as fixed, rule-based constraints or as a single chosen ethical theory embedded at design time. This overlooks a fundamental property of human-system interaction settings: ethical preferences vary across individuals and groups, evolve with context, and may conflict, while still needing to remain within a legally and regulatorily defined hard-ethics envelope (e.g., safety and compliance constraints). This paper advocates a shift from static ethical rules to runtime ethical reasoning for self-adaptive systems, where ethical preferences are treated as runtime requirements that must be elicited, represented, and continuously revised as stakeholders and situations change. We argue that satisfying such requirements demands explicit ethics-based negotiation to manage ethical trade-offs among multiple humans who interact with, are represented by, or are affected by a system. We identify key challenges, ethical uncertainty, conflicts among ethical values (including human, societal, and environmental drivers), and multi-dimensional/multi-party/multi-driver negotiation, and outline research directions and questions toward ethically self-adaptive systems.", "published": "2026-02-19T14:57:30Z", "updated": "2026-02-19T14:57:30Z", "authors": ["Marco Autili", "Gianluca Filippone", "Mashal Afzal Memon", "Patrizio Pelliccione"], "pdf_url": "https://arxiv.org/pdf/2602.17426v1"}
{"id": "http://arxiv.org/abs/2302.01894v5", "title": "Understanding the Issues, Their Causes and Solutions in Microservices Systems: An Empirical Study", "summary": "Many small to large organizations have adopted the Microservices Architecture (MSA) style to develop and deliver their core businesses. Despite the popularity of MSA in the software industry, there is a limited evidence-based and thorough understanding of the types of issues (e.g., errors, faults, failures, and bugs) that microservices system developers experience, the causes of the issues, and the solutions as potential fixing strategies to address the issues. To ameliorate this gap, we conducted a mixed-methods empirical study that collected data from 2,641 issues from the issue tracking systems of 15 open-source microservices systems on GitHub, 15 interviews, and an online survey completed by 150 practitioners from 42 countries across 6 continents. Our analysis led to comprehensive taxonomies for the issues, causes, and solutions. The findings of this study informthat Technical Debt, Continuous Integration and Delivery, Exception Handling, Service Execution and Communication, and Security are the most dominant issues in microservices systems. Furthermore, General Programming Errors, Missing Features and Artifacts, and Invalid Configuration and Communication are the main causes behind the issues. Finally, we found 177 types of solutions that can be applied to fix the identified issues. Based on our study results, we propose a future research framework that outlines key problem dimensions and actionable study strategies to support the engineering of emergent and next-generation microservices systems.", "published": "2023-02-03T18:08:03Z", "updated": "2026-02-19T14:31:09Z", "authors": ["Muhammad Waseem", "Peng Liang", "Aakash Ahmad", "Arif Ali Khan", "Mojtaba Shahin", "Pekka Abrahamsson", "Ali Rezaei Nasab", "Tommi Mikkonen"], "pdf_url": "https://arxiv.org/pdf/2302.01894v5"}
{"id": "http://arxiv.org/abs/2602.17365v1", "title": "Computer-Using World Model", "summary": "Agents operating in complex software environments benefit from reasoning about the consequences of their actions, as even a single incorrect user interface (UI) operation can derail long, artifact-preserving workflows. This challenge is particularly acute for computer-using scenarios, where real execution does not support counterfactual exploration, making large-scale trial-and-error learning and planning impractical despite the environment being fully digital and deterministic. We introduce the Computer-Using World Model (CUWM), a world model for desktop software that predicts the next UI state given the current state and a candidate action. CUWM adopts a two-stage factorization of UI dynamics: it first predicts a textual description of agent-relevant state changes, and then realizes these changes visually to synthesize the next screenshot. CUWM is trained on offline UI transitions collected from agents interacting with real Microsoft Office applications, and further refined with a lightweight reinforcement learning stage that aligns textual transition predictions with the structural requirements of computer-using environments. We evaluate CUWM via test-time action search, where a frozen agent uses the world model to simulate and compare candidate actions before execution. Across a range of Office tasks, world-model-guided test-time scaling improves decision quality and execution robustness.", "published": "2026-02-19T13:48:29Z", "updated": "2026-02-19T13:48:29Z", "authors": ["Yiming Guan", "Rui Yu", "John Zhang", "Lu Wang", "Chaoyun Zhang", "Liqun Li", "Bo Qiao", "Si Qin", "He Huang", "Fangkai Yang", "Pu Zhao", "Lukas Wutschitz", "Samuel Kessler", "Huseyin A Inan", "Robert Sim", "Saravan Rajmohan", "Qingwei Lin", "Dongmei Zhang"], "pdf_url": "https://arxiv.org/pdf/2602.17365v1"}
{"id": "http://arxiv.org/abs/2602.17320v1", "title": "Socio-Technical Well-Being of Quantum Software Communities: An Overview on Community Smells", "summary": "Quantum computing has gained significant attention due to its potential to solve computational problems beyond the capabilities of classical computers. With major corporations and academic institutions investing in quantum hardware and software, there has been a rise in the development of quantum-enabled systems, particularly within open-source communities. However, despite the promising nature of quantum technologies, these communities face critical socio-technical challenges, including the emergence of socio-technical anti-patterns known as community smells. These anti-patterns, prevalent in open-source environments, have the potential to negatively impact both product quality and community health by introducing technical debt and amplifying architectural and code smells. Despite the importance of these socio-technical factors, there remains a scarcity of research investigating their influence within quantum open-source communities. This work aims to address this gap by providing a first step in analyzing the socio-technical well-being of quantum communities through a cross-sectional study. By understanding the socio-technical dynamics at play, it is expected that foundational knowledge can be established to mitigate the risks associated with community smells and ensure the long-term sustainability of open-source quantum initiatives.", "published": "2026-02-19T12:35:08Z", "updated": "2026-02-19T12:35:08Z", "authors": ["Stefano Lambiase", "Manuel De Stefano", "Fabio Palomba", "Filomena Ferrucci", "Andrea De Lucia"], "pdf_url": "https://arxiv.org/pdf/2602.17320v1"}
{"id": "http://arxiv.org/abs/2512.12507v3", "title": "ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs", "summary": "Analyzing non-compilable C/C++ submodules without a resolved build environment remains a critical bottleneck for industrial software evolution. Traditional static analysis tools often fail in these scenarios due to their reliance on successful compilation, while Large Language Models (LLMs) lack the structural context necessary to reason about complex program logic. We introduce ATLAS, a Python-based CLI that generates unified multi-view representations for large-scale C/C++ projects with high accuracy, achieving success rates up to 96.80% for CFGs and 91.38% for DFGs. ATLAS is characterized by: (i) inter-procedural, type-aware analysis across function boundaries; (ii) support for both full and partial analysis of non-compilable projects; (iii) graph optimizations such as variable collapsing and node blacklisting; and (iv) synchronized multi-view graphs that align syntax, execution paths, and data-flow logic. Evaluating ATLAS with DeepSeek V3.2 for automated test generation demonstrates a 34.71% increase in line coverage and 32.66% in branch coverage, matching or exceeding the performance of the symbolic execution tool KLEE on complex projects. With polynomial scalability, ATLAS provides a robust infrastructure for generating the information-dense datasets required by next-generation, graph-aware ML4SE models.\n  Video demonstration: https://youtu.be/QGuJZhj9CTA Tool github repository: https://github.com/jaid-monwar/ATLAS-multi-view-code-representation-tool.git", "published": "2025-12-14T01:11:11Z", "updated": "2026-02-19T10:45:42Z", "authors": ["Jaid Monwar Chowdhury", "Ahmad Farhan Shahriar Chowdhury", "Humayra Binte Monwar", "Mahmuda Naznin"], "pdf_url": "https://arxiv.org/pdf/2512.12507v3"}
{"id": "http://arxiv.org/abs/2602.17237v1", "title": "Disjunction Composition of BDD Transition Systems for Model-Based Testing", "summary": "We introduce a compositional approach to model-based test generation in Behavior-Driven Development (BDD). BDD is an agile methodology in which system behavior is specified through textual scenarios that, in our approach, are translated into transition systems used for model-based testing. This paper formally defines disjunction composition, to combine BDD transition systems that represent alternative system behaviors. Disjunction composition allows for modeling and testing the integrated behavior while ensuring that the testing power of the original set of scenarios is preserved. This is proved using a symbolic semantics for BDD transition systems, with the property that the symbolic equivalence of two BDD transition systems guarantees that they fail the same test cases. Also, we demonstrate the potential of disjunction composition by applying the composition in an industrial case study.", "published": "2026-02-19T10:33:50Z", "updated": "2026-02-19T10:33:50Z", "authors": ["Tannaz Zameni", "Petra van den Bos", "Arend Rensink"], "pdf_url": "https://arxiv.org/pdf/2602.17237v1"}
{"id": "http://arxiv.org/abs/2602.17193v1", "title": "The Case for HTML First Web Development", "summary": "Since its introduction in the early 90s, the web has become the largest application platform available globally. HyperText Markup Language (HTML) has been an essential part of the web since the beginning, as it allows defining webpages in a tree-like manner, including semantics and content. Although the web was never meant to be an application platform, it evolved as such, especially since the early 2000s, as web application frameworks became available. While the emergence of frameworks made it easier than ever to develop complex applications, it also put HTML on the back burner. As web standards caught up, especially with milestones such as HTML5, the gap between the web platform and frameworks was reduced. HTML First development emphasizes this shift and puts focus on literally using HTML first when possible, while encouraging minimalism familiar from the early days of the web. It seems HTML-oriented web development can provide clear benefits to developers, especially when it is combined with comple- mentary approaches, such as embracing hypermedia and moving a large part of application logic to the server side. In the context of the htmx project, it was observed that moving towards HTML can reduce the size of a codebase greatly while leading to maintenance and development benefits due to the increased conceptual simplicity. Holotype-based comparisons for content-oriented websites show performance benefits, and the same observation was confirmed by a small case study where the Yle website was converted to follow HTML First principles. In short, the HTML First approach seems to have clear advantages for web developers, while there are open questions related to the magnitude of the benefits and the alignment with the recent trend of AI-driven web development.", "published": "2026-02-19T09:23:21Z", "updated": "2026-02-19T09:23:21Z", "authors": ["Juho Vepsäläinen"], "pdf_url": "https://arxiv.org/pdf/2602.17193v1"}
{"id": "http://arxiv.org/abs/2602.17183v1", "title": "Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering", "summary": "Large language models (LLMs) increasingly assist software engineering tasks that require reasoning over long code contexts, yet their robustness under varying input conditions remains unclear. We conduct a systematic study of long-context code question answering using controlled ablations that test sensitivity to answer format, distractors, and context scale. Extending LongCodeBench Python dataset with new COBOL and Java question-answer sets, we evaluate state-of-the-art models under three settings: (i) shuffled multiple-choice options, (ii) open-ended questions and (iii) needle-in-a-haystack contexts containing relevant and adversarially irrelevant information. Results show substantial performance drops in both shuffled multiple-choice options and open-ended questions, and brittle behavior in the presence of irrelevant cues. Our findings highlight limitations of current long-context evaluations and provide a broader benchmark for assessing code reasoning in both legacy and modern systems.", "published": "2026-02-19T09:05:03Z", "updated": "2026-02-19T09:05:03Z", "authors": ["Kishan Maharaj", "Nandakishore Menon", "Ashita Saxena", "Srikanth Tamilselvam"], "pdf_url": "https://arxiv.org/pdf/2602.17183v1"}
{"id": "http://arxiv.org/abs/2601.01569v3", "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators", "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms that struggle with long-horizon tasks due to fragile multi-turn dependencies and context drift. We present CaveAgent, a framework that shifts tool use from ``LLM-as-Text-Generator'' to ``LLM-as-Runtime-Operator.'' CaveAgent introduces a dual-stream architecture that inverts the conventional paradigm: rather than treating the LLM's text context as the primary workspace with tools as auxiliary, CaveAgent elevates the persistent Python runtime as the central locus of state, with a lightweight semantic stream serving as its orchestrator. Beyond leveraging code generation to resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, CaveAgent introduces \\textit{Stateful Runtime Management}: it injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns, unlike existing code-based approaches that remain text-bound. CaveAgent further provides a runtime-integrated skill management system that extends the Agent Skills open standard, enabling ecosystem interoperability through executable skill injections. This persistence mechanism serves as a high-fidelity external memory that reduces context drift in multi-turn interactions and preserves processed data for downstream applications without information loss. Evaluations show consistent improvement across challenging benchmarks, enabling CaveAgent to handle data scales that cause context overflow in both JSON-based and code-based agents. The accessible runtime state further provides programmatically verifiable feedback, enabling automated evaluation and reward signal generation without human annotation and establishing a structural foundation for future research in Reinforcement Learning with Verifiable Rewards (RLVR).", "published": "2026-01-04T15:32:47Z", "updated": "2026-02-19T07:07:15Z", "authors": ["Maohao Ran", "Zhenglin Wan", "Cooper Lin", "Yanting Zhang", "Hongyu Xin", "Hongwei Fan", "Yibo Xu", "Beier Luo", "Yaxin Zhou", "Wangbo Zhao", "Lijie Yang", "Lang Feng", "Fuchao Yang", "Jingxuan Wu", "Yiqiao Huang", "Chendong Ma", "Dailing Jiang", "Jianbo Deng", "Sirui Han", "Yang You", "Bo An", "Yike Guo", "Jun Song"], "pdf_url": "https://arxiv.org/pdf/2601.01569v3"}
{"id": "http://arxiv.org/abs/2602.17131v1", "title": "Quantifying Competitive Relationships Among Open-Source Software Projects", "summary": "Throughout the history of software, evolution has occurred in cycles of rise and fall driven by competition, and open-source software (OSS) is no exception. This cycle is accelerating, particularly in rapidly evolving domains such as web development and deep learning. However, the impact of competitive relationships among OSS projects on their survival remains unclear, and there are risks of losing a competitive edge to rivals. To address this, this study proposes a new automated method called ``Mutual Impact Analysis of OSS (MIAO)'' to quantify these competitive relationships. The proposed method employs a structural vector autoregressive model and impulse response functions, normally used in macroeconomic analysis, to analyze the interactions among OSS projects. In an empirical analysis involving mining and analyzing 187 OSS project groups, MIAO identified projects that were forced to cease development owing to competitive influences with up to 81\\% accuracy, and the resulting features supported predictive experiments that anticipate cessation one year ahead with up to 77\\% accuracy. This suggests that MIAO could be a valuable tool for OSS project maintainers to understand the dynamics of OSS ecosystems and predict the rise and fall of OSS projects.", "published": "2026-02-19T07:06:34Z", "updated": "2026-02-19T07:06:34Z", "authors": ["Yuki Takei", "Toshiaki Aoki", "Chaiyong Ragkhitwetsagul"], "pdf_url": "https://arxiv.org/pdf/2602.17131v1"}
{"id": "http://arxiv.org/abs/2506.02529v2", "title": "Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs", "summary": "Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.", "published": "2025-06-03T07:08:21Z", "updated": "2026-02-19T06:53:03Z", "authors": ["Nguyen-Khang Le", "Quan Minh Bui", "Minh Ngoc Nguyen", "Hiep Nguyen", "Trung Vo", "Son T. Luu", "Shoshin Nomura", "Minh Le Nguyen"], "pdf_url": "https://arxiv.org/pdf/2506.02529v2"}
{"id": "http://arxiv.org/abs/2602.17112v1", "title": "Multi-Ecosystem Modeling of OSS Project Sustainability", "summary": "Many OSS projects join foundations such as Apache, Eclipse, and OSGeo, to aid their immediate plans and improve long-term prospects by getting governance advice, incubation support, and community-building mechanisms. But foundations differ in their policies, funding models, and support strategies. Moreover, since projects joining these foundations are diverse, coming at different lifecycle stages and having different needs, it can be challenging to decide on the appropriate project-foundation match and on the project-specific plan for sustainability.\n  Here, we present an empirical study and quantitative analysis of the sustainability of incubator projects in the Apache, Eclipse, and OSGeo foundations, and, additionally, of OSS projects from GitHub outside of foundations. We develop foundation-specific sustainability models and a project triage, based on projects' sociotechnical trace profiles, and demonstrate their effectiveness across the foundations. Our results show that our models with triage can effectively forecast sustainability outcomes not only within but across foundations. In addition, the generalizability of the framework allows us to apply the approach to GitHub projects outside the foundations. We complement our findings with actionable recovery strategies from previous work and apply them to case studies of failed incubator projects. Our study highlights the value of sociotechnical frameworks in characterizing and addressing software project sustainability issues.", "published": "2026-02-19T06:17:54Z", "updated": "2026-02-19T06:17:54Z", "authors": ["Arjun Ashok", "Nafiz Imtiaz Khan", "Swati Singhvi", "Stefan Stanciulescu", "Zhouhao Wang", "Vladimir Filkov"], "pdf_url": "https://arxiv.org/pdf/2602.17112v1"}
{"id": "http://arxiv.org/abs/2602.17091v1", "title": "What to Cut? Predicting Unnecessary Methods in Agentic Code Generation", "summary": "Agentic Coding, powered by autonomous agents such as GitHub Copilot and Cursor, enables developers to generate code, tests, and pull requests from natural language instructions alone. While this accelerates implementation, it produces larger volumes of code per pull request, shifting the burden from implementers to reviewers. In practice, a notable portion of AI-generated code is eventually deleted during review, yet reviewers must still examine such code before deciding to remove it. No prior work has explored methods to help reviewers efficiently identify code that will be removed.In this paper, we propose a prediction model that identifies functions likely to be deleted during PR review. Our results show that functions deleted for different reasons exhibit distinct characteristics, and our model achieves an AUC of 87.1%. These findings suggest that predictive approaches can help reviewers prioritize their efforts on essential code.", "published": "2026-02-19T05:29:32Z", "updated": "2026-02-19T05:29:32Z", "authors": ["Kan Watanabe", "Tatsuya Shirai", "Yutaro Kashiwa", "Hajimu Iida"], "pdf_url": "https://arxiv.org/pdf/2602.17091v1"}
{"id": "http://arxiv.org/abs/2602.17084v1", "title": "How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses", "summary": "The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including structural features, and examine human reviewer response in terms of review activity, response timing, sentiment, and merge outcomes. We find that AI coding agents exhibit distinct PR description styles, which are associated with differences in reviewer engagement, response time, and merge outcomes. We observe notable variation across agents in both reviewer interaction metrics and merge rates. These findings highlight the role of pull request presentation and reviewer interaction dynamics in human-AI collaborative software development.", "published": "2026-02-19T05:06:31Z", "updated": "2026-02-19T05:06:31Z", "authors": ["Kan Watanabe", "Rikuto Tsuchida", "Takahiro Monno", "Bin Huang", "Kazuma Yamasaki", "Youmei Fan", "Kazumasa Shimari", "Kenichi Matsumoto"], "pdf_url": "https://arxiv.org/pdf/2602.17084v1"}
{"id": "http://arxiv.org/abs/2602.17037v1", "title": "Wink: Recovering from Misbehaviors in Coding Agents", "summary": "Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatically recovering from agentic misbehaviors at scale. We first introduce a taxonomy of misbehaviors grounded in an analysis of production traffic, identifying three primary categories: Specification Drift, Reasoning Problems, and Tool Call Failures, which we find occur in about 30% of all agent trajectories.\n  To address these issues, we developed a lightweight, asynchronous self-intervention system named Wink. Wink observes agent trajectories and provides targeted course-correction guidance to nudge the agent back to a productive path. We evaluated our system on over 10,000 real world agent trajectories and found that it successfully resolves 90% of the misbehaviors that require a single intervention. Furthermore, a live A/B test in our production environment demonstrated that our system leads to a statistically significant reduction in Tool Call Failures, Tokens per Session and Engineer Interventions per Session. We present our experience designing and deploying this system, offering insights into the challenges of building resilient agentic systems at scale.", "published": "2026-02-19T03:15:00Z", "updated": "2026-02-19T03:15:00Z", "authors": ["Rahul Nanda", "Chandra Maddila", "Smriti Jha", "Euna Mehnaz Khan", "Matteo Paltenghi", "Satish Chandra"], "pdf_url": "https://arxiv.org/pdf/2602.17037v1"}
{"id": "http://arxiv.org/abs/2602.17018v1", "title": "Not Only for Developers: Exploring Plugin Maintenance for Knowledge-Centric Communities", "summary": "The adoption of third-party libraries has become integral to modern software development, leading to large ecosystems such as PyPI, NPM, and Maven, where contributors typically share the technical expertise to sustain extensions. In communities that are not exclusively composed of developers, however, maintaining plugin ecosystems can present different challenges. In this early results paper, we study Obsidian, a knowledge--centric platform whose community is focused on writing, organization, and creativity--has built a substantial plugin ecosystem despite not being developer--centric. We investigate what kinds of plugins exist within this hybrid ecosystem and establish a foundation for understanding how they are maintained. Using repository mining and LLM-based topic modeling on a representative sample of 396 plugins, we identify six topics related to knowledge management and tooling, which is (i) dynamic editing and organization, (ii) interface and layouts, (iii) creative writing and productivity, (iv) knowledge sync solutions, (v) linking and script tools, and (vi) workflow enhancements tools. Furthermore, analysis of the Pull Requests from these plugins show that much software evolution has been performed on these ecosystem. These findings suggest that even in mixed communities, plugin ecosystems can develop recognizable engineering structures, motivating future work that highlight three different research directions with six research questions related to the health and sustainability of these non-developer ecosystems.", "published": "2026-02-19T02:30:05Z", "updated": "2026-02-19T02:30:05Z", "authors": ["Giovanni Rosa", "David Moreno-Lumbreras", "Raula Gaikovina Kula"], "pdf_url": "https://arxiv.org/pdf/2602.17018v1"}
{"id": "http://arxiv.org/abs/2602.16997v1", "title": "Exploring LLMs for User Story Extraction from Mockups", "summary": "User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how combining these techniques with large language models (LLMs) enables agile and automated generation of user stories from mockups. To this end, we present a case study that analyzes the ability of LLMs to extract user stories from high-fidelity mockups, both with and without the inclusion of a glossary of the Language Extended Lexicon (LEL) in the prompts. Our results demonstrate that incorporating the LEL significantly enhances the accuracy and suitability of the generated user stories. This approach represents a step forward in the integration of AI into requirements engineering, with the potential to improve communication between users and developers.", "published": "2026-02-19T01:42:45Z", "updated": "2026-02-19T01:42:45Z", "authors": ["Diego Firmenich", "Leandro Antonelli", "Bruno Pazos", "Fabricio Lozada", "Leonardo Morales"], "pdf_url": "https://arxiv.org/pdf/2602.16997v1"}
