{"id": "http://arxiv.org/abs/2512.03971v1", "title": "Approximate Optimal Active Learning of Decision Trees", "summary": "We consider the problem of actively learning an unknown binary decision tree using only membership queries, a setting in which the learner must reason about a large hypothesis space while maintaining formal guarantees. Rather than enumerating candidate trees or relying on heuristic impurity or entropy measures, we encode the entire space of bounded-depth decision trees symbolically in SAT formulas. We propose a symbolic method for active learning of decision trees, in which approximate model counting is used to estimate the reduction of the hypothesis space caused by each potential query, enabling near-optimal query selection without full model enumeration. The resulting learner incrementally strengthens a CNF representation based on observed query outcomes, and approximate model counter ApproxMC is invoked to quantify the remaining version space in a sound and scalable manner. Additionally, when ApproxMC stagnates, a functional equivalence check is performed to verify that all remaining hypotheses are functionally identical. Experiments on decision trees show that the method reliably converges to the correct model using only a handful of queries, while retaining a rigorous SAT-based foundation suitable for formal analysis and verification.", "published": "2025-12-03T17:03:39Z", "updated": "2025-12-03T17:03:39Z", "authors": ["Zunchen Huang", "Chenglu Jin"], "pdf_url": "https://arxiv.org/pdf/2512.03971v1"}
{"id": "http://arxiv.org/abs/2512.03926v1", "title": "Tunable Automation in Automated Program Verification", "summary": "Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints.\n  We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level.\n  We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.", "published": "2025-12-03T16:27:01Z", "updated": "2025-12-03T16:27:01Z", "authors": ["Alexander Y. Bai", "Chris Hawblitzel", "Andrea Lattuada"], "pdf_url": "https://arxiv.org/pdf/2512.03926v1"}
{"id": "http://arxiv.org/abs/2511.18538v4", "title": "From Code Foundation Models to Agents and Applications: A Comprehensive Survey and Practical Guide to Code Intelligence", "summary": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.", "published": "2025-11-23T17:09:34Z", "updated": "2025-12-03T15:30:51Z", "authors": ["Jian Yang", "Xianglong Liu", "Weifeng Lv", "Ken Deng", "Shawn Guo", "Lin Jing", "Yizhi Li", "Shark Liu", "Xianzhen Luo", "Yuyu Luo", "Changzai Pan", "Ensheng Shi", "Yingshui Tan", "Renshuai Tao", "Jiajun Wu", "Xianjie Wu", "Zhenhe Wu", "Daoguang Zan", "Chenchen Zhang", "Wei Zhang", "He Zhu", "Terry Yue Zhuo", "Kerui Cao", "Xianfu Cheng", "Jun Dong", "Shengjie Fang", "Zhiwei Fei", "Xiangyuan Guan", "Qipeng Guo", "Zhiguang Han", "Joseph James", "Tianqi Luo", "Renyuan Li", "Yuhang Li", "Yiming Liang", "Congnan Liu", "Jiaheng Liu", "Qian Liu", "Ruitong Liu", "Tyler Loakman", "Xiangxin Meng", "Chuang Peng", "Tianhao Peng", "Jiajun Shi", "Mingjie Tang", "Boyang Wang", "Haowen Wang", "Yunli Wang", "Fanglin Xu", "Zihan Xu", "Fei Yuan", "Ge Zhang", "Jiayi Zhang", "Xinhao Zhang", "Wangchunshu Zhou", "Hualei Zhu", "King Zhu", "Bryan Dai", "Aishan Liu", "Zhoujun Li", "Chenghua Lin", "Tianyu Liu", "Chao Peng", "Kai Shen", "Libo Qin", "Shuangyong Song", "Zizheng Zhan", "Jiajun Zhang", "Jie Zhang", "Zhaoxiang Zhang", "Bo Zheng"], "pdf_url": "https://arxiv.org/pdf/2511.18538v4"}
{"id": "http://arxiv.org/abs/2512.03868v1", "title": "A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software", "summary": "Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.", "published": "2025-12-03T15:20:10Z", "updated": "2025-12-03T15:20:10Z", "authors": ["Shree Hari Bittugondanahalli Indra Kumar", "Lilia Rodrigues Sampaio", "André Martin", "Andrey Brito", "Christof Fetzer"], "pdf_url": "https://arxiv.org/pdf/2512.03868v1"}
{"id": "http://arxiv.org/abs/2506.03013v2", "title": "Cataloguing Hugging Face Models to Software Engineering Activities: Automation and Findings", "summary": "Context: Open-source Pre-Trained Models (PTMs) provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs to support the reliable identification and reuse of models for SE. Objective: To address this gap, we derive a taxonomy encompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a popular open-source ML repository, Hugging Face (HF). Method: Our repository mining study followed a five-phase pipeline: (i) identification SE tasks from the literature; (ii) collection of PTM data from the HF API, including model card descriptions and metadata, and the abstracts of the associated arXiv papers; (iii) text processing to ensure consistency; (iv) a two-phase validation of SE relevance, involving humans and LLM assistance, supported by five pilot studies with human annotators and a generalization test; (v) and data analysis. This process yielded a curated catalogue of 2,205 SE PTMs. Results: We find that most SE PTMs target code generation and coding, emphasizing implementation over early or late development stages. In terms of ML tasks, text generation dominates within SE PTMs. Notably, the number of SE PTMs has increased markedly since 2023 Q2, while evaluation remains limited: only 9.6% report benchmark results, mostly scoring below 50%. Conclusions: Our catalogue reveals documentation and transparency gaps, highlights imbalances across SDLC phases, and provides a foundation for automated SE scenarios, such as the sampling and selection of suitable PTMs.", "published": "2025-06-03T15:51:17Z", "updated": "2025-12-03T14:18:58Z", "authors": ["Alexandra González", "Xavier Franch", "David Lo", "Silverio Martínez-Fernández"], "pdf_url": "https://arxiv.org/pdf/2506.03013v2"}
{"id": "http://arxiv.org/abs/2512.03815v1", "title": "Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate", "summary": "Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.", "published": "2025-12-03T14:03:32Z", "updated": "2025-12-03T14:03:32Z", "authors": ["Shayan Ghasemnezhad", "Samarth KaPatel", "Sofia Nikiforova", "Giacinto Paolo Saggese", "Paul Smith", "Heanh Sok"], "pdf_url": "https://arxiv.org/pdf/2512.03815v1"}
{"id": "http://arxiv.org/abs/2512.03635v1", "title": "Formal Analysis of the Sigmoid Function and Formal Proof of the Universal Approximation Theorem", "summary": "This paper presents a formalized analysis of the sigmoid function and a fully mechanized proof of the Universal Approximation Theorem (UAT) in Isabelle/HOL, a higher-order logic theorem prover. The sigmoid function plays a fundamental role in neural networks; yet, its formal properties, such as differentiability, higher-order derivatives, and limit behavior, have not previously been comprehensively mechanized in a proof assistant. We present a rigorous formalization of the sigmoid function, proving its monotonicity, smoothness, and higher-order derivatives. We provide a constructive proof of the UAT, demonstrating that neural networks with sigmoidal activation functions can approximate any continuous function on a compact interval. Our work identifies and addresses gaps in Isabelle/HOL's formal proof libraries and introduces simpler methods for reasoning about the limits of real functions. By exploiting theorem proving for AI verification, our work enhances trust in neural networks and contributes to the broader goal of verified and trustworthy machine learning.", "published": "2025-12-03T10:16:02Z", "updated": "2025-12-03T10:16:02Z", "authors": ["Dustin Bryant", "Jim Woodcock", "Simon Foster"], "pdf_url": "https://arxiv.org/pdf/2512.03635v1"}
{"id": "http://arxiv.org/abs/2501.14402v3", "title": "On the Effectiveness of Microservices Tactics and Patterns to Reduce Energy Consumption: An Experimental Study on Trade-Offs", "summary": "Context: Microservice-based systems have established themselves in the software industry. However, sustainability-related legislation and the growing costs of energy-hungry software increase the importance of energy efficiency for these systems. While some proposals for architectural tactics and patterns exist, their effectiveness as well as potential trade-offs on other quality attributes (QAs) remain unclear. Goal: We therefore aim to study the effectiveness of microservices tactics and patterns to reduce energy consumption, as well as potential trade-offs with performance and maintainability. Method: Using the open-source Online Boutique system, we conducted a controlled experiment with three tactics and three patterns, and analyzed the impact of each technique compared to a baseline. We also tested with three levels of simulated request loads (low, medium, high). Results: Request load moderated the effectiveness of reducing energy consumption. All techniques (tactics and patterns) reduced the energy consumption for at least one load level, up to 5.6%. For performance, the techniques could negatively impact response time by increasing it by up to 25.9%, while some also decreased it by up to 72.5%. Two techniques increased the throughput, by 1.9% and 34.0%. For maintainability, three techniques had a negative, one a positive, and two no impact. Conclusion: Some techniques reduced energy consumption while also improving performance. However, these techniques usually involved a trade-off in maintainability, e.g., via more code duplication and module coupling. Overall, all techniques significantly reduced energy consumption at higher loads, but most of them sacrificed one of the other QAs. This highlights that the real challenge is not simply reducing energy consumption of microservices, but to achieve energy efficiency.", "published": "2025-01-24T11:15:23Z", "updated": "2025-12-03T08:37:24Z", "authors": ["Xingwen Xiao", "Chushu Gao", "Justus Bogner"], "pdf_url": "https://arxiv.org/pdf/2501.14402v3"}
{"id": "http://arxiv.org/abs/2509.08863v3", "title": "GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation", "summary": "Large Language Models (LLMs) have demonstrated substantial progress in task automation and natural language understanding. However, without domain expertise in geographic information science (GIS), they continue to encounter limitations including reduced accuracy and unstable performance when processing complex tasks. To address these challenges, we propose GeoJSON Agents-a novel multi-agent LLM architecture specifically designed for geospatial analysis. This framework transforms natural language instructions into structured GeoJSON operations through two LLM enhancement techniques: Function Calling and Code Generation. The architecture integrates three core components: task parsing, agent collaboration, and result integration. The Planner agent systematically decomposes user-defined tasks into executable subtasks, while Worker agents perform spatial data processing and analysis either by invoking predefined function APIs or by generating and executing Python-based analytical code. The system produces reusable, standards-compliant GeoJSON outputs through iterative refinement. To evaluate both approaches, we constructed a benchmark comprising 70 tasks spanning basic, intermediate, and advanced complexity levels, conducting experiments with OpenAI's GPT-4o as the core model. Results indicate that the Code Generation-based agent achieved 97.14% accuracy, while the Function Calling-based agent attained 85.71%-both significantly outperforming the best-performing general-purpose model (48.57%). Comparative analysis reveals Code Generation offers superior flexibility for complex, open-ended tasks, whereas Function Calling provides enhanced execution stability for structured operations. This study represents the first systematic integration of GeoJSON data with a multi-agent LLM framework and provides empirical evidence comparing two mainstream enhancement methodologies in geospatial context.", "published": "2025-09-10T03:43:46Z", "updated": "2025-12-03T07:42:29Z", "authors": ["Qianqian Luo", "Qingming Lin", "Liuchang Xu", "Sensen Wu", "Ruichen Mao", "Chao Wang", "Hailin Feng", "Bo Huang", "Zhenhong Du"], "pdf_url": "https://arxiv.org/pdf/2509.08863v3"}
{"id": "http://arxiv.org/abs/2512.03421v1", "title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization", "summary": "Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.", "published": "2025-12-03T03:55:18Z", "updated": "2025-12-03T03:55:18Z", "authors": ["Hexiang Xu", "Hengyuan Liu", "Yonghao Wu", "Xiaolan Kang", "Xiang Chen", "Yong Liu"], "pdf_url": "https://arxiv.org/pdf/2512.03421v1"}
{"id": "http://arxiv.org/abs/2512.03420v1", "title": "HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines", "summary": "Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation.\n  To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.", "published": "2025-12-03T03:55:09Z", "updated": "2025-12-03T03:55:09Z", "authors": ["Kang Yang", "Yunhang Zhang", "Zichuan Li", "GuanHong Tao", "Jun Xu", "XiaoJing Liao"], "pdf_url": "https://arxiv.org/pdf/2512.03420v1"}
{"id": "http://arxiv.org/abs/2409.02977v2", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "summary": "The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external resources and tools. To date, LLM-based agents have been applied and shown remarkable effectiveness in Software Engineering (SE). The synergy between multiple agents and human interaction brings further promise in tackling complex real-world SE problems. In this work, we present a comprehensive and systematic survey on LLM-based agents for SE. We collect 124 papers and categorize them from two perspectives, i.e., the SE and agent perspectives. In addition, we discuss open challenges and future directions in this critical domain. The repository of this survey is at https://github.com/FudanSELab/Agent4SE-Paper-List.", "published": "2024-09-04T15:59:41Z", "updated": "2025-12-03T03:33:35Z", "authors": ["Junwei Liu", "Kaixin Wang", "Yixuan Chen", "Xin Peng", "Zhenpeng Chen", "Lingming Zhang", "Yiling Lou"], "pdf_url": "https://arxiv.org/pdf/2409.02977v2"}
