{"id": "http://arxiv.org/abs/2601.00783v1", "title": "Improving Router Security using BERT", "summary": "Previous work on home router security has shown that using system calls to train a transformer-based language model built on a BERT-style encoder using contrastive learning is effective in detecting several types of malware, but the performance remains limited at low false positive rates. In this work, we demonstrate that using a high-fidelity eBPF-based system call sensor, together with contrastive augmented learning (which introduces controlled mutations of negative samples), improves detection performance at a low false positive rate. In addition, we introduce a network packet abstraction language that enables the creation of a pipeline similar to network packet data, and we show that network behavior provides complementary detection signals-yielding improved performance for network-focused malware at low false positive rates. Lastly, we implement these methods in an online router anomaly detection framework to validate the approach in an Internet of Things (IoT) deployment environment.", "published": "2026-01-02T18:34:27Z", "updated": "2026-01-02T18:34:27Z", "authors": ["John Carter", "Spiros Mancoridis", "Pavlos Protopapas", "Brian Mitchell", "Benji Lilley"], "pdf_url": "https://arxiv.org/pdf/2601.00783v1"}
{"id": "http://arxiv.org/abs/2601.00752v1", "title": "Three results on twisted $G-$codes and skew twisted $G-$codes", "summary": "In this paper we solve an open question formulated in the original paper of twisted skew group codes regarding when a twisted skew group code is checkable. Also, we prove that all ideals of dimension 3 over a twisted group algebra are abelian group codes, generalising another previous result over group algebras. Finally, we prove a bound on the dimension and distance of a twisted group code, as well as when such bound is reached.", "published": "2026-01-02T17:16:09Z", "updated": "2026-01-02T17:16:09Z", "authors": ["Alvaro Otero Sanchez"], "pdf_url": "https://arxiv.org/pdf/2601.00752v1"}
{"id": "http://arxiv.org/abs/2512.22501v2", "title": "NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization", "summary": "Ensuring the authenticity and ownership of digital images is increasingly challenging as modern editing tools enable highly realistic forgeries. Existing image protection systems mainly rely on digital watermarking, which is susceptible to sophisticated digital attacks. To address this limitation, we propose a hybrid optical-digital framework that incorporates physical authentication cues during image formation and preserves them through a learned reconstruction process. At the optical level, a phase mask in the camera aperture produces a Null-space Optical Watermark (NOWA) that lies in the Null Space of the imaging operator and therefore remains invisible in the captured image. Then, a Null-Space Network (NSN) performs measurement-consistent reconstruction that delivers high-quality protected images while preserving the NOWA signature. The proposed design enables tamper localization by projecting the image onto the camera's null space and detecting pixel-level inconsistencies. Our design preserves perceptual quality, resists common degradations such as compression, and establishes a structural security asymmetry: without access to the optical or NSN parameters, adversaries cannot forge the NOWA signature. Experiments with simulations and a prototype camera demonstrate competitive performance in terms of image quality preservation, and tamper localization accuracy compared to state-of-the-art digital watermarking and learning-based authentication methods.", "published": "2025-12-27T06:57:20Z", "updated": "2026-01-02T17:11:37Z", "authors": ["Edwin Vargas", "Jhon Lopez", "Henry Arguello", "Ashok Veeraraghavan"], "pdf_url": "https://arxiv.org/pdf/2512.22501v2"}
{"id": "http://arxiv.org/abs/2510.07806v3", "title": "Ancora: Accurate Intrusion Recovery for Web Applications", "summary": "Modern web application recovery presents a critical dilemma. Coarse-grained snapshot rollbacks cause unacceptable data loss for legitimate users. Surgically removing an attack's impact is hindered by a fundamental challenge in high-concurrency environments: it is difficult to attribute resulting file and database modifications to a specific attack-related request. We present Ancora, a system for precise intrusion recovery in web applications without invasive instrumentation. Ancora first isolates the full sequence of syscalls triggered by a single malicious request. Based on this sequence, Ancora addresses file and database modifications separately. To trace file changes, it builds a provenance graph that reveals all modifications, including those by exploit-spawned processes. To attribute database operations, a more difficult challenge due to connection pooling, Ancora introduces a novel spatiotemporal anchor. This anchor uses the request's network connection tuple and active time window to pinpoint exact database operations. With all malicious file and database operations precisely identified, Ancora performs a unified rewind and selective replay recovery. It reverts the system to a clean snapshot taken before the attack, then selectively re-applies only legitimate operations to both the file system and database. This completely removes the attack's effects while preserving concurrent legitimate data. We evaluated Ancora on 10 web applications and 20 CVE-based attack scenarios with concurrency up to 150 connections. Experiments demonstrate Ancora achieves 99.9% recovery accuracy with manageable overhead: up to 19.8% response latency increase and 17.8% QPS decrease in worst cases, and recovery throughput of 110.7 database operations per second and 27.2 affected files per second, effectively preserving legitimate data.", "published": "2025-10-09T05:33:09Z", "updated": "2026-01-02T14:47:23Z", "authors": ["Yihao Peng", "Biao Ma", "Hai Wan", "Xibin Zhao"], "pdf_url": "https://arxiv.org/pdf/2510.07806v3"}
{"id": "http://arxiv.org/abs/2512.08809v2", "title": "PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration", "summary": "With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_χ$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.", "published": "2025-12-09T17:03:59Z", "updated": "2026-01-02T14:03:16Z", "authors": ["Yi Liu", "Weixiang Han", "Chengjun Cai", "Xingliang Yuan", "Cong Wang"], "pdf_url": "https://arxiv.org/pdf/2512.08809v2"}
{"id": "http://arxiv.org/abs/2501.14931v5", "title": "Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer", "summary": "This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically-optimal latency of $2δ$, or one round-trip, i.e., requiring only one network trip (duration $δ$) for writing a transaction and one for reading it.\n  To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, which independently process transactions and append them to local logs. Replicas assigns a timestamp and a sequence number to each transaction in their logs, allowing clients to extract valuable metadata about the transactions and the system state. Later on, clients retrieve these logs and extract transactions (and associated metadata) from them.\n  Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then show pod-core, a protocol that satisfies properties such as transaction confirmation within $2δ$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that single-shot auctions can be realized using the pod notion and observe that it is also sufficient for other popular applications.", "published": "2025-01-24T21:41:03Z", "updated": "2026-01-02T13:34:22Z", "authors": ["Orestis Alpos", "Bernardo David", "Jakov Mitrovski", "Odysseas Sofikitis", "Dionysis Zindros"], "pdf_url": "https://arxiv.org/pdf/2501.14931v5"}
{"id": "http://arxiv.org/abs/2601.00627v1", "title": "Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits", "summary": "Intelligent Connected Vehicles (ICVs) are a core component of modern transportation systems, and their security is crucial as it directly relates to user safety. Despite prior research, most existing studies focus only on specific sub-components of ICVs due to their inherent complexity. As a result, there is a lack of systematic understanding of ICV vulnerabilities. Moreover, much of the current literature relies on human subjective analysis, such as surveys and interviews, which tends to be high-level and unvalidated, leaving a significant gap between theoretical findings and real-world attacks. To address this issue, we conducted the first large-scale empirical study on ICV vulnerabilities. We began by analyzing existing ICV security literature and summarizing the prevailing taxonomies in terms of vulnerability locations and types. To evaluate their real-world relevance, we collected a total of 649 exploitable vulnerabilities, including 592 from eight ICV vulnerability discovery competitions, Anonymous Cup, between January 2023 and April 2024, covering 48 different vehicles. The remaining 57 vulnerabilities were submitted daily by researchers. Based on this dataset, we assessed the coverage of existing taxonomies and identified several gaps, discovering one new vulnerability location and 13 new vulnerability types. We further categorized these vulnerabilities into 6 threat types (e.g., privacy data breach) and 4 risk levels (ranging from low to critical) and analyzed participants' skills and the types of ICVs involved in the competitions. This study provides a comprehensive and data-driven analysis of ICV vulnerabilities, offering actionable insights for researchers, industry practitioners, and policymakers. To support future research, we have made our vulnerability dataset publicly available.", "published": "2026-01-02T09:56:44Z", "updated": "2026-01-02T09:56:44Z", "authors": ["Yuelin Wang", "Yuqiao Ning", "Yanbang Sun", "Xiaofei Xie", "Zhihua Xie", "Yang Chen", "Zhen Guo", "Shihao Xue", "Junjie Wang", "Sen Chen"], "pdf_url": "https://arxiv.org/pdf/2601.00627v1"}
{"id": "http://arxiv.org/abs/2512.09699v2", "title": "Device Independent Quantum Secret Sharing Using Multiparty Pseudo-telepathy Game", "summary": "Device-independent quantum secret sharing (DI-QSS) provides security against untrusted quantum devices. While device-independent quantum key distribution (DI-QKD) using Mermin-Peres magic square game [Zhen et al., Phys. Rev. Lett, 2023] has been proposed, we present the first DI-QSS protocol based on a pseudo-telepathy parity game without requiring dedicated rounds and specific basis configuration, unlike CHSH-based DI-QSS schemes [Zhang et al., Phys. Rev. A, 2024]. Our scheme simultaneously certifies device-independence and key generation using a single test, achieving optimal performance for a seven-qubit GHZ state configuration. Security against collective attacks is analyzed, and a positive key rate is obtained under white noise and photon loss. Moreover, we show a bitwise advantage over the previous protocol for producing the same raw key length.", "published": "2025-12-10T14:46:43Z", "updated": "2026-01-02T06:12:25Z", "authors": ["Santanu Majhi", "Goutam Paul"], "pdf_url": "https://arxiv.org/pdf/2512.09699v2"}
{"id": "http://arxiv.org/abs/2601.00572v1", "title": "Toward a Dynamic Intellectual Property Protection Model in High-Growth SMEs", "summary": "This paper addresses the challenges faced by High-Growth Small-to-Medium Enterprises (HG-SMEs) in balancing intellectual property (IP) protection with open innovation during periods of rapid growth. Despite developing valuable IP assets that drive success, HG-SMEs often struggle with cybersecurity concerns related to IP theft and data exfiltration amidst resource constraints and the competing demands of expansion. We examine the intersection of cybersecurity, IP protection and rapid scaling - an area currently underexplored in existing literature. Drawing on Dynamic Capabilities (DC), Knowledge-based View (KBV) and open innovation theoretical frameworks, we introduce a conceptual framework to guide HG-SMEs in effectively managing valuable IP assets. This research-in-progress paper outlines a qualitative methodology to validate and refine the model. By addressing the research question of how HG-SMEs manage cybersecurity to protect valuable IP assets, we aim to provide practical guidance for high-growth, technology-driven companies navigating the tension between robust IP protection and collaborative innovation.", "published": "2026-01-02T05:19:13Z", "updated": "2026-01-02T05:19:13Z", "authors": ["Sam Pitruzzello", "Sean Maynard", "Atif Ahmad"], "pdf_url": "https://arxiv.org/pdf/2601.00572v1"}
{"id": "http://arxiv.org/abs/2601.00571v1", "title": "Threat Intelligence Driven IP Protection for Entrepreneurial SMEs", "summary": "Entrepreneurial small to medium enterprises face significant cybersecurity challenges when developing valuable intellectual property (IP). This paper addresses the critical gap in research on how E-SMEs can protect their IP assets from cybersecurity threats through effective threat intelligence and IP protection activities. Drawing on Dynamic Capabilities and Knowledge-Based View theoretical frameworks, we propose the Threat Intelligence-driven IP Protection (TI-IPP) model. This conceptual model features to modes of operation, closed IP development and open innovation, enabling E-SMEs to adapt their IP protection and knowledge management strategies. The model incorporates four key phases: sensing opportunities and threats, seizing opportunities, knowledge transfer, and organizational transformation. By integrating cybersecurity threat intelligence with IP protection practices, E-SMEs can develop capabilities to safeguard valuable IP while maintaining competitive advantage. This research-in-progress paper outlines a qualitative research methodology using multiple case studies to validate and refine the proposed model for practical application in resource-constrained entrepreneurial environments.", "published": "2026-01-02T05:16:04Z", "updated": "2026-01-02T05:16:04Z", "authors": ["Sam Pitruzzello", "Atif Ahmad", "Sean Maynard"], "pdf_url": "https://arxiv.org/pdf/2601.00571v1"}
{"id": "http://arxiv.org/abs/2601.00566v1", "title": "Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems", "summary": "Low-Rank Adaptation (LoRA) has become a popular solution for fine-tuning large language models (LLMs) in federated settings, dramatically reducing update costs by introducing trainable low-rank matrices. However, when integrated with frameworks like FedIT, LoRA introduces a critical vulnerability: clients submit $A$ and $B$ matrices separately, while only their product $AB$ determines the model update, yet this composite is never directly verified. We propose Gradient Assembly Poisoning (GAP), a novel attack that exploits this blind spot by crafting individually benign $A$ and $B$ matrices whose product yields malicious updates. GAP operates without access to training data or inter-client coordination and remains undetected by standard anomaly detectors. We identify four systemic vulnerabilities in LoRA-based federated systems and validate GAP across LLaMA, ChatGLM, and GPT-2. GAP consistently induces degraded or biased outputs while preserving surface fluency, reducing BLEU by up to 14.5\\%, increasing factual and grammatical errors by over 800\\%, and maintaining 92.6\\% long-form response length. These results reveal a new class of stealthy, persistent threats in distributed LoRA fine-tuning.", "published": "2026-01-02T04:42:56Z", "updated": "2026-01-02T04:42:56Z", "authors": ["Yueyan Dong", "Minghui Xu", "Qin Hu", "Yinhao Xiao", "Qi Luo", "Yechao Zhang", "Yue Zhang", "Xiuzhen Cheng"], "pdf_url": "https://arxiv.org/pdf/2601.00566v1"}
{"id": "http://arxiv.org/abs/2601.00559v1", "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?", "summary": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.", "published": "2026-01-02T04:17:36Z", "updated": "2026-01-02T04:17:36Z", "authors": ["Jason Quantrill", "Noura Khajehnouri", "Zihan Guo", "Manar H. Alalfi"], "pdf_url": "https://arxiv.org/pdf/2601.00559v1"}
{"id": "http://arxiv.org/abs/2601.00556v1", "title": "Cyberscurity Threats and Defense Mechanisms in IoT network", "summary": "The rapid proliferation of Internet of Things (IoT) technologies, projected to exceed 30 billion interconnected devices by 2030, has significantly escalated the complexity of cybersecurity challenges. This survey aims to provide a comprehensive analysis of vulnerabilities, threats, and defense mechanisms, specifically focusing on the integration of network and application layers within real-time monitoring and decision-making systems. Employing an integrative review methodology, 59 scholarly articles published between 2009 and 2024 were selected from databases such as IEEE Xplore, ScienceDirect, and PubMed, utilizing keywords related to IoT vulnerabilities and security attacks. Key findings identify critical threat categories, including sensor vulnerabilities, Denial-of-Service (DoS) attacks, and public cloud insecurity. Conversely, the study highlights advanced defense approaches leveraging Artificial Intelligence (AI) for anomaly detection, Blockchain for decentralized trust, and Zero Trust Architecture (ZTA) for continuous verification. This paper contributes a novel five-layer IoT model and outlines future research directions involving quantum computing and 6G networks to bolster IoT ecosystem resilience.", "published": "2026-01-02T04:06:03Z", "updated": "2026-01-02T04:06:03Z", "authors": ["Trung Dao", "Minh Nguyen", "Son Do", "Hoang Tran"], "pdf_url": "https://arxiv.org/pdf/2601.00556v1"}
{"id": "http://arxiv.org/abs/2601.00523v1", "title": "The CoinAlg Bind: Profitability-Fairness Tradeoffs in Collective Investment Algorithms", "summary": "Collective Investment Algorithms (CoinAlgs) are increasingly popular systems that deploy shared trading strategies for investor communities. Their goal is to democratize sophisticated -- often AI-based -- investing tools. We identify and demonstrate a fundamental profitability-fairness tradeoff in CoinAlgs that we call the CoinAlg Bind: CoinAlgs cannot ensure economic fairness without losing profit to arbitrage. We present a formal model of CoinAlgs, with definitions of privacy (incomplete algorithm disclosure) and economic fairness (value extraction by an adversarial insider). We prove two complementary results that together demonstrate the CoinAlg Bind. First, privacy in a CoinAlg is a precondition for insider attacks on economic fairness. Conversely, in a game-theoretic model, lack of privacy, i.e., transparency, enables arbitrageurs to erode the profitability of a CoinAlg. Using data from Uniswap, a decentralized exchange, we empirically study both sides of the CoinAlg Bind. We quantify the impact of arbitrage against transparent CoinAlgs. We show the risks posed by a private CoinAlg: Even low-bandwidth covert-channel information leakage enables unfair value extraction.", "published": "2026-01-02T01:23:25Z", "updated": "2026-01-02T01:23:25Z", "authors": ["Andrés Fábrega", "James Austgen", "Samuel Breckenridge", "Jay Yu", "Amy Zhao", "Sarah Allen", "Aditya Saraf", "Ari Juels"], "pdf_url": "https://arxiv.org/pdf/2601.00523v1"}
