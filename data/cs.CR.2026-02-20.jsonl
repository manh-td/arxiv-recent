{"id": "http://arxiv.org/abs/2510.15173v2", "title": "Beyond the Voice: Inertial Sensing of Mouth Motion for High Security Speech Verification", "summary": "Voice interfaces are increasingly used in high stakes domains such as mobile banking, smart home security, and hands free healthcare. Meanwhile, modern generative models have made high quality voice forgeries inexpensive and easy to create, eroding confidence in voice authentication alone. To strengthen protection against such attacks, we present a second authentication factor that combines acoustic evidence with the unique motion patterns of a speaker's lower face. By placing lightweight inertial sensors around the mouth to capture mouth opening and evolving lower facial geometry, our system records a distinct motion signature with strong discriminative power across individuals. We built a prototype and recruited 43 participants to evaluate the system under four conditions seated, walking on level ground, walking on stairs, and speaking with different language backgrounds (native vs. non native English). Across all scenarios, our approach consistently achieved a median equal error rate (EER) of 0.01 or lower, indicating that mouth movement data remain robust under variations in gait, posture, and spoken language. We discuss specific use cases where this second line of defense could provide tangible security benefits to voice authentication systems.", "published": "2025-10-16T22:26:18Z", "updated": "2026-02-20T18:09:26Z", "authors": ["Ynes Ineza", "Muhammad A. Ullah", "Abdul Serwadda", "Aurore Munyaneza"], "pdf_url": "https://arxiv.org/pdf/2510.15173v2"}
{"id": "http://arxiv.org/abs/2510.03770v3", "title": "Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data", "summary": "Ensuring the trustworthiness of data from distributed and resource-constrained environments, such as Wireless Sensor Networks or IoT devices, is critical. Existing Reversible Data Hiding (RDH) methods for scalar data suffer from low embedding capacity and poor intrinsic mixing between host data and watermark. This paper introduces Hiding in the Imaginary Domain with Data Encryption (H[i]dden), a novel framework based on complex number arithmetic for simultaneous information embedding and encryption. The H[i]dden framework offers perfect reversibility, in-principle unlimited watermark size, and intrinsic data-watermark mixing. The paper further introduces two protocols: H[i]dden-EG, for joint reversible data hiding and encryption, and H[i]dden-AggP, for privacy-preserving aggregation of watermarked data, based on partially homomorphic encryption. These protocols provide efficient and resilient solutions for data integrity, provenance and confidentiality, serving as a foundation for new schemes based on the algebraic properties of the complex domain.", "published": "2025-10-04T10:39:48Z", "updated": "2026-02-20T17:56:48Z", "authors": ["David Megias"], "pdf_url": "https://arxiv.org/pdf/2510.03770v3"}
{"id": "http://arxiv.org/abs/2602.18370v1", "title": "Drawing the LINE: Cryptographic Analysis and Security Improvements for the LINE E2EE Protocol", "summary": "LINE has emerged as one of the most popular communication platforms in many East Asian countries, including Thailand and Japan, with millions of active users. Therefore, it is essential to understand its security guarantees. In this work, we present the first provable security analysis of the LINE version two (LINEv2) messaging protocol, focusing on its cryptographic guarantees in a real-world setting. We capture the architecture and security of the LINE messaging protocol by modifying the Multi-Stage Key Exchange (MSKE) model, a framework for analysing cryptographic protocols under adversarial conditions. While LINEv2 achieves basic security properties such as key indistinguishability and message authentication, we highlight the lack of forward secrecy (FS) and post-compromise security (PCS). To address this, we introduce a stronger version of the LINE protocol, introducing FS and PCS to LINE, analysing and benchmarking our results.", "published": "2026-02-20T17:26:47Z", "updated": "2026-02-20T17:26:47Z", "authors": ["Benjamin Dowling", "Prosanta Gope", "Mehr U Nisa", "Bhagya Wimalasiri"], "pdf_url": "https://arxiv.org/pdf/2602.18370v1"}
{"id": "http://arxiv.org/abs/2602.18352v1", "title": "Qualitative Coding Analysis through Open-Source Large Language Models: A User Study and Design Recommendations", "summary": "Qualitative data analysis is labor-intensive, yet the privacy risks associated with commercial Large Language Models (LLMs) often preclude their use in sensitive research. To address this, we introduce ChatQDA, an on-device framework powered by open-source LLMs designed for privacy-preserving open coding. Our mixed-methods user study reveals that while participants rated the system highly for usability and perceived efficiency, they exhibited \"conditional trust\", valuing the tool for surface-level extraction while questioning its interpretive nuance and consistency. Furthermore, despite the technical security of local deployment, participants reported epistemic uncertainty regarding data protection, suggesting that invisible security measures are insufficient to foster trust. We conclude with design recommendations for local-first analysis tools that prioritize verifiable privacy and methodological rigor.", "published": "2026-02-20T17:04:02Z", "updated": "2026-02-20T17:04:02Z", "authors": ["Tung T. Ngo", "Dai Nguyen Van", "Anh-Minh Nguyen", "Phuong-Anh Do", "Anh Nguyen-Quoc"], "pdf_url": "https://arxiv.org/pdf/2602.18352v1"}
{"id": "http://arxiv.org/abs/2505.05370v3", "title": "Walrus: An Efficient Decentralized Storage Network", "summary": "Decentralized storage systems face a fundamental trade-off between replication overhead, recovery efficiency, and security guarantees. Current approaches either rely on full replication, incurring substantial storage costs, or employ trivial erasure coding schemes that struggle with efficient recovery especially under high storage-node churn. We present Walrus, a novel decentralized blob storage system that addresses these limitations through multiple technical innovations. At the core of Walrus is RedStuff, a two-dimensional erasure coding protocol that achieves high security with only 4.5x replication factor, while enabling self-healing recovery that requires bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$ in traditional systems). Crucially, RedStuff is the first protocol to support storage challenges in asynchronous networks, preventing adversaries from exploiting network delays to pass verification without actually storing data. Walrus also introduces a novel multi-stage epoch change protocol that efficiently handles storage node churn while maintaining uninterrupted availability during committee transitions. Our system incorporates authenticated data structures to defend against malicious clients and ensures data consistency throughout storage and retrieval processes. Experimental evaluation demonstrates that Walrus achieves practical performance at scale, making it suitable for a wide range of decentralized applications requiring high-integrity, available blob storage with reasonable overhead.", "published": "2025-05-08T16:06:41Z", "updated": "2026-02-20T16:24:40Z", "authors": ["George Danezis", "Giacomo Giuliari", "Eleftherios Kokoris Kogias", "Markus Legner", "Jean-Pierre Smith", "Alberto Sonnino", "Karl Wüst"], "pdf_url": "https://arxiv.org/pdf/2505.05370v3"}
{"id": "http://arxiv.org/abs/2602.18304v1", "title": "FeatureBleed: Inferring Private Enriched Attributes From Sparsity-Optimized AI Accelerators", "summary": "Backend enrichment is now widely deployed in sensitive domains such as product recommendation pipelines, healthcare, and finance, where models are trained on confidential data and retrieve private features whose values influence inference behavior while remaining hidden from the API caller. This paper presents the first hardware-level backend retrieval data-stealing attack, showing that accelerator optimizations designed for performance can directly undermine data confidentiality and bypass state-of-the-art privacy defenses.\n  Our attack, FEATUREBLEED, exploits zero-skipping in AI accelerators to infer private backend-retrieved features solely through end-to-end timing, without relying on power analysis, DVFS manipulation, or shared-cache side channels. We evaluate FEATUREBLEED on three datasets spanning medical and non-medical domains: Texas-100X (clinical records), OrganAMNIST (medical imaging), and Census-19 (socioeconomic data). We further evaluate FEATUREBLEED across three hardware backends (Intel AVX, Intel AMX, and NVIDIA A100) and three model architectures (DNNs, CNNs, and hybrid CNN-MLP pipelines), demonstrating that the leakage generalizes across CPU and GPU accelerators, data modalities, and application domains, with an adversarial advantage of up to 98.87 percentage points.\n  Finally, we identify the root cause of the leakage as sparsity-driven zero-skipping in modern hardware. We quantify the privacy-performance-power trade-off: disabling zero-skipping increases Intel AMX per-operation energy by up to 25 percent and incurs 100 percent performance overhead. We propose a padding-based defense that masks timing leakage by equalizing responses to the worst-case execution time, achieving protection with only 7.24 percent average performance overhead and no additional power cost.", "published": "2026-02-20T16:01:16Z", "updated": "2026-02-20T16:01:16Z", "authors": ["Darsh Asher", "Farshad Dizani", "Joshua Kalyanapu", "Rosario Cammarota", "Aydin Aysu", "Samira Mirbagher Ajorpaz"], "pdf_url": "https://arxiv.org/pdf/2602.18304v1"}
{"id": "http://arxiv.org/abs/2602.18285v1", "title": "Detecting PowerShell-based Fileless Cryptojacking Attacks Using Machine Learning", "summary": "With the emergence of remote code execution (RCE) vulnerabilities in ubiquitous libraries and advanced social engineering techniques, threat actors have started conducting widespread fileless cryptojacking attacks. These attacks have become effective with stealthy techniques based on PowerShell-based exploitation in Windows OS environments. Even if attacks are detected and malicious scripts removed, processes may remain operational on victim endpoints, creating a significant challenge for detection mechanisms. In this paper, we conducted an experimental study with a collected dataset on detecting PowerShell-based fileless cryptojacking scripts. The results showed that Abstract Syntax Tree (AST)-based fine-tuned CodeBERT achieved a high recall rate, proving the importance of the use of AST integration and fine-tuned pre-trained models for programming language.", "published": "2026-02-20T15:32:15Z", "updated": "2026-02-20T15:32:15Z", "authors": ["Said Varlioglu", "Nelly Elsayed", "Murat Ozer", "Zag ElSayed", "John M. Emmert"], "pdf_url": "https://arxiv.org/pdf/2602.18285v1"}
{"id": "http://arxiv.org/abs/2602.18270v1", "title": "Many Tools, Few Exploitable Vulnerabilities: A Survey of 246 Static Code Analyzers for Security", "summary": "Static security analysis is a widely used technique for detecting software vulnerabilities across a wide range of weaknesses, application domains, and programming languages. While prior work surveyed static analyzes for specific weaknesses or application domains, no overview of the entire security landscape exists. We present a systematic literature review of 246 static security analyzers concerning their targeted vulnerabilities, application domains, analysis techniques, evaluation methods, and limitations. We observe that most analyzers focus on a limited set of weaknesses, that the vulnerabilities they detect are rarely exploitable, and that evaluations use custom benchmarks that are too small to enable robust assessment.", "published": "2026-02-20T14:52:18Z", "updated": "2026-02-20T14:52:18Z", "authors": ["Kevin Hermann", "Sven Peldszus", "Thorsten Berger"], "pdf_url": "https://arxiv.org/pdf/2602.18270v1"}
{"id": "http://arxiv.org/abs/2503.07199v4", "title": "How Well Can Differential Privacy Be Audited in One Run?", "summary": "Recent methods for auditing the privacy of machine learning algorithms have improved computational efficiency by simultaneously intervening on multiple training examples in a single training run. Steinke et al. (2024) prove that one-run auditing indeed lower bounds the true privacy parameter of the audited algorithm, and give impressive empirical results. Their work leaves open the question of how precisely one-run auditing can uncover the true privacy parameter of an algorithm, and how that precision depends on the audited algorithm. In this work, we characterize the maximum achievable efficacy of one-run auditing and show that the key barrier to its efficacy is interference between the observable effects of different data elements. We present new conceptual approaches to minimize this barrier, towards improving the performance of one-run auditing of real machine learning algorithms.", "published": "2025-03-10T11:32:30Z", "updated": "2026-02-20T13:19:03Z", "authors": ["Amit Keinan", "Moshe Shenfeld", "Katrina Ligett"], "pdf_url": "https://arxiv.org/pdf/2503.07199v4"}
{"id": "http://arxiv.org/abs/2602.18172v1", "title": "Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning", "summary": "Capture-the-Flag (CTF) competitions serve as gateways into offensive cybersecurity, yet they often present steep barriers for novices due to complex toolchains and opaque workflows. Recently, agentic AI frameworks for cybersecurity promise to lower these barriers by automating and coordinating penetration testing tasks. However, their role in shaping novice learning remains underexplored.\n  We present a human-centered, mixed-methods case study examining how agentic AI frameworks -- here Cybersecurity AI (CAI) -- mediates novice entry into CTF-based penetration testing. An undergraduate student without prior hacking experience attempted to approach performance benchmarks from a national cybersecurity challenge using CAI. Quantitative performance metrics were complemented by structured reflective analysis of learning progression and AI interaction patterns.\n  Our thematic analysis suggest that agentic AI reduces initial entry barriers by providing overview, structure and guidance, thereby lowering the cognitive workload during early engagement. Quantitatively, the observed extensive exploration of strategies and low per-strategy execution time potetially facilitatates cybersecurity training on meta, i.e. strategic levels. At the same time, AI-assisted cybersecurity education introduces new challenges related to trust, dependency, and responsible use. We discuss implications for human-centered AI-supported cybersecurity education and outline open questions for future research.", "published": "2026-02-20T12:20:36Z", "updated": "2026-02-20T12:20:36Z", "authors": ["Cathrin Schachner", "Jasmin Wachter"], "pdf_url": "https://arxiv.org/pdf/2602.18172v1"}
{"id": "http://arxiv.org/abs/2602.18165v1", "title": "Uncertainty-Aware Jamming Mitigation with Active RIS: A Robust Stackelberg Game Approach", "summary": "Malicious jamming presents a pervasive threat to the secure communications, where the challenge becomes increasingly severe due to the growing capability of the jammer allowing the adaptation to legitimate transmissions. This paper investigates the jamming mitigation by leveraging an active reconfigurable intelligent surface (ARIS), where the channel uncertainties are particularly addressed for robust anti-jamming design. Towards this issue, we adopt the Stackelberg game formulation to model the strategic interaction between the legitimate side and the adversary, acting as the leader and follower, respectively. We prove the existence of the game equilibrium and adopt the backward induction method for equilibrium analysis. We first derive the optimal jamming policy as the follower's best response, which is then incorporated into the legitimate-side optimization for robust anti-jamming design. We address the uncertainty issue and reformulate the legitimate-side problem by exploiting the error bounds to combat the worst-case jamming attacks. The problem is decomposed within a block successive upper bound minimization (BSUM) framework to tackle the power allocation, transceiving beamforming, and active reflection, respectively, which are iterated towards the robust jamming mitigation scheme. Simulation results are provided to demonstrate the effectiveness of the proposed scheme in protecting the legitimate transmissions under uncertainties, and the superior performance in terms of jamming mitigation as compared with the baselines.", "published": "2026-02-20T12:02:01Z", "updated": "2026-02-20T12:02:01Z", "authors": ["Xiao Tang", "Zhen Ma", "Limeng Dong", "Yichen Wang", "Qinghe Du", "Dusit Niyato", "Zhu Han"], "pdf_url": "https://arxiv.org/pdf/2602.18165v1"}
{"id": "http://arxiv.org/abs/2412.11471v2", "title": "TrapFlow: Controllable Website Fingerprinting Defense via Dynamic Backdoor Learning", "summary": "Website fingerprinting (WF) attacks, which covertly monitor user communications to identify the web pages they visit, pose a serious threat to user privacy. Existing WF defenses attempt to reduce attack accuracy by disrupting traffic patterns, but attackers can retrain their models to adapt, making these defenses ineffective. Meanwhile, their high overhead limits deployability. To overcome these limitations, we introduce a novel controllable website fingerprinting defense called TrapFlow based on backdoor learning. TrapFlow exploits the tendency of neural networks to memorize subtle patterns by injecting crafted trigger sequences into targeted website traffic, causing the attacker model to build incorrect associations during training. If the attacker attempts to adapt by training on such noisy data, TrapFlow ensures that the model internalizes the trigger as a dominant feature, leading to widespread misclassification across unrelated websites. Conversely, if the attacker ignores these patterns and trains only on clean data, the trigger behaves as an adversarial patch at inference time, causing model misclassification. To achieve this dual effect, we optimize the trigger using a Fast Levenshtein like distance to maximize both its learnability and its distinctiveness from normal traffic. Experiments show that TrapFlow significantly reduces the accuracy of the RF attack from 99 percent to 6 percent with 74 percent data overhead. This compares favorably against two state of the art defenses: FRONT reduces accuracy by only 2 percent at a similar overhead, while Palette achieves 32 percent accuracy but with 48 percent more overhead. We further validate the practicality of our method in a real Tor network environment.", "published": "2024-12-16T06:12:56Z", "updated": "2026-02-20T11:34:15Z", "authors": ["Siyuan Liang", "Jiajun Gong", "Tianmeng Fang", "Aishan Liu", "Tao Wang", "Xiaochun Cao", "Dacheng Tao", "Ee-Chien Chang"], "pdf_url": "https://arxiv.org/pdf/2412.11471v2"}
{"id": "http://arxiv.org/abs/2601.19500v3", "title": "Reuse of Public Keys Across UTXO and Account-Based Cryptocurrencies", "summary": "It is well known that reusing cryptocurrency addresses undermines privacy. This also applies if the same addresses are used in different cryptocurrencies. Nevertheless, cross-chain address reuse appears to be a recurring phenomenon, especially in EVM-based designs. Previous works performed either direct address matching, or basic format conversion, to identify such cases. However, seemingly incompatible address formats e.g., in Bitcoin and Ethereum, can also be derived from the same public keys, since they rely on the same cryptographic primitives. In this paper, we therefore focus on the underlying public keys to discover reuse within, as well as across, different cryptocurrency networks, enabling us to also match incompatible address formats. Specifically, we analyze key reuse across Bitcoin, Ethereum, Litecoin, Dogecoin, Zcash and Tron. Our results reveal that cryptographic keys are extensively and actively reused across these networks, negatively impacting both privacy and security of their users. We are hence the first to expose and quantify cross-chain key reuse between UTXO and account-based cryptocurrencies. Moreover, we devise novel clustering methods across these different cryptocurrency networks that do not rely on heuristics and instead link entities by their knowledge of the underlying secret key.", "published": "2026-01-27T11:38:09Z", "updated": "2026-02-20T09:22:30Z", "authors": ["Rainer Stütz", "Nicholas Stifter", "Melitta Dragaschnig", "Bernhard Haslhofer", "Aljosha Judmayer"], "pdf_url": "https://arxiv.org/pdf/2601.19500v3"}
{"id": "http://arxiv.org/abs/2602.18082v1", "title": "AndroWasm: an Empirical Study on Android Malware Obfuscation through WebAssembly", "summary": "In recent years, stealthy Android malware has increasingly adopted sophisticated techniques to bypass automatic detection mechanisms and harden manual analysis. Adversaries typically rely on obfuscation, anti-repacking, steganography, poisoning, and evasion techniques to AI-based tools, and in-memory execution to conceal malicious functionality.\n  In this paper, we investigate WebAssembly (Wasm) as a novel technique for hiding malicious payloads and evading traditional static analysis and signature-matching mechanisms. While Wasm is typically employed to render specific gaming activities and interact with the native components in web browsers, we provide an in-depth analysis on the mechanisms Android may employ to include Wasm modules in its execution pipeline. Additionally, we provide Proofs-of-Concept to demonstrate a threat model in which an attacker embeds and executes malicious routines, effectively bypassing IoC detection by industrial state-of-the-art tools, like VirusTotal and MobSF.", "published": "2026-02-20T09:15:51Z", "updated": "2026-02-20T09:15:51Z", "authors": ["Diego Soi", "Silvia Lucia Sanna", "Lorenzo Pisu", "Leonardo Regano", "Giorgio Giacinto"], "pdf_url": "https://arxiv.org/pdf/2602.18082v1"}
{"id": "http://arxiv.org/abs/2602.18079v1", "title": "Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars", "summary": "Many adversarial attacks on autonomous-driving perception models fail to cause system-level failures once deployed in a full driving stack. The main reason for such ineffectiveness is that once deployed in a system (e.g., within a simulator), attacks tend to be spatially or temporally short-lived, due to the vehicle's dynamics, hence rarely influencing the vehicle behaviour. In this paper, we address both limitations by introducing a system-level attack in which multiple dynamic elements (e.g., two pedestrians) carry adversarial patches (e.g., on cloths) and jointly amplify their effect through coordination and motion. We evaluate our attacks in the CARLA simulator using a state-of-the-art autonomous driving agent. At the system level, single-pedestrian attacks fail in all runs (out of 10), while dynamic collusion by two pedestrians induces full vehicle stops in up to 50\\% of runs, with static collusion yielding no successful attack at all. These results show that system-level failures arise only when adversarial signals persist over time and are amplified through coordinated actors, exposing a gap between model-level robustness and end-to-end safety.", "published": "2026-02-20T09:09:24Z", "updated": "2026-02-20T09:09:24Z", "authors": ["Masoud Jamshidiyan Tehrani", "Marco Gabriel", "Jinhan Kim", "Paolo Tonella"], "pdf_url": "https://arxiv.org/pdf/2602.18079v1"}
{"id": "http://arxiv.org/abs/2602.18063v1", "title": "Distributed Security: From Isolated Properties to Synergistic Trust", "summary": "Over the past four decades, distributed security has undergone a remarkable transformation -- from crash-fault tolerant protocols designed for controlled environments to sophisticated Byzantine-resilient architectures operating in open, adversarial settings. This vision paper examines this evolution and argues for a fundamental shift in how we approach distributed security: from studying individual security properties in isolation to understanding their synergistic combinations. We begin by conclude four foundational properties, \\textit{agreement, consistency, privacy, verifiability, accountability}. We trace their theoretical origins and practical maturation. We then demonstrate how the frontier of research now lies at the intersection of these properties, where their fusion creates capabilities that neither property could achieve alone. Looking forward, we identify critical research challenges: discovering new security properties driven by emerging applications, developing systematic frameworks for property convergence, managing the computational overhead of cryptographic primitives in high-performance consensus layers, and addressing post-quantum and human-factor challenges. The future of distributed security lies not in improving individual properties, but in understanding and harnessing their synergies to build a singular fabric of trust.", "published": "2026-02-20T08:31:18Z", "updated": "2026-02-20T08:31:18Z", "authors": ["Minghui Xu"], "pdf_url": "https://arxiv.org/pdf/2602.18063v1"}
{"id": "http://arxiv.org/abs/2602.18034v1", "title": "Separating Non-Interactive Classical Verification of Quantum Computation from Falsifiable Assumptions", "summary": "Mahadev [SIAM J. Comput. 2022] introduced the first protocol for classical verification of quantum computation based on the Learning-with-Errors (LWE) assumption, achieving a 4-message interactive scheme. This breakthrough naturally raised the question of whether fewer messages are possible in the plain model. Despite its importance, this question has remained unresolved.\n  In this work, we prove that there is no quantum black-box reduction of non-interactive classical verification of quantum computation of $\\textsf{QMA}$ to any falsifiable assumption. Here, \"non-interactive\" means that after an instance-independent setup, the protocol consists of a single message. This constitutes a strong negative result given that falsifiable assumptions cover almost all standard assumptions used in cryptography, including LWE. Our separation holds under the existence of a $\\textsf{QMA} \\text{-} \\textsf{QCMA}$ gap problem. Essentially, these problems require a slightly stronger assumption than $\\textsf{QMA}\\neq \\textsf{QCMA}$. To support the existence of such problems, we present a construction relative to a quantum unitary oracle.", "published": "2026-02-20T07:27:25Z", "updated": "2026-02-20T07:27:25Z", "authors": ["Mohammed Barhoush", "Tomoyuki Morimae", "Ryo Nishimaki", "Takashi Yamakawa"], "pdf_url": "https://arxiv.org/pdf/2602.18034v1"}
{"id": "http://arxiv.org/abs/2602.11495v2", "title": "Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models", "summary": "Jailbreaking large language models (LLMs) has emerged as a critical security challenge with the widespread deployment of conversational AI systems. Adversarial users exploit these models through carefully crafted prompts to elicit restricted or unsafe outputs, a phenomenon commonly referred to as Jailbreaking. Despite numerous proposed defense mechanisms, attackers continue to develop adaptive prompting strategies, and existing models remain vulnerable. This motivates approaches that examine the internal behavior of LLMs rather than relying solely on prompt-level defenses. In this work, we study jailbreaking from both security and interpretability perspectives by analyzing how internal representations differ between jailbreak and benign prompts. We conduct a systematic layer-wise analysis across multiple open-source models, including GPT-J, LLaMA, Mistral, and the state-space model Mamba, and identify consistent latent-space patterns associated with harmful inputs. We then propose a tensor-based latent representation framework that captures structure in hidden activations and enables lightweight jailbreak detection without model fine-tuning or auxiliary LLM-based detectors. We further demonstrate that the latent signals can be used to actively disrupt jailbreak execution at inference time. On an abliterated LLaMA-3.1-8B model, selectively bypassing high-susceptibility layers blocks 78% of jailbreak attempts while preserving benign behavior on 94% of benign prompts. This intervention operates entirely at inference time and introduces minimal overhead, providing a scalable foundation for achieving stronger coverage by incorporating additional attack distributions or more refined susceptibility thresholds. Our results provide evidence that jailbreak behavior is rooted in identifiable internal structures and suggest a complementary, architecture-agnostic direction for improving LLM security.", "published": "2026-02-12T02:43:17Z", "updated": "2026-02-20T05:13:21Z", "authors": ["Sri Durga Sai Sowmya Kadali", "Evangelos E. Papalexakis"], "pdf_url": "https://arxiv.org/pdf/2602.11495v2"}
{"id": "http://arxiv.org/abs/2602.17973v1", "title": "PenTiDef: Enhancing Privacy and Robustness in Decentralized Federated Intrusion Detection Systems against Poisoning Attacks", "summary": "The increasing deployment of Federated Learning (FL) in Intrusion Detection Systems (IDS) introduces new challenges related to data privacy, centralized coordination, and susceptibility to poisoning attacks. While significant research has focused on protecting traditional FL-IDS with centralized aggregation servers, there remains a notable gap in addressing the unique challenges of decentralized FL-IDS (DFL-IDS). This study aims to address the limitations of traditional centralized FL-IDS by proposing a novel defense framework tailored for the decentralized FL-IDS architecture, with a focus on privacy preservation and robustness against poisoning attacks. We propose PenTiDef, a privacy-preserving and robust defense framework for DFL-IDS, which incorporates Distributed Differential Privacy (DDP) to protect data confidentiality and utilizes latent space representations (LSR) derived from neural networks to detect malicious updates in the decentralized model aggregation context. To eliminate single points of failure and enhance trust without a centralized aggregation server, PenTiDef employs a blockchain-based decentralized coordination mechanism that manages model aggregation, tracks update history, and supports trust enforcement through smart contracts. Experimental results on CIC-IDS2018 and Edge-IIoTSet demonstrate that PenTiDef consistently outperforms existing defenses (e.g., FLARE, FedCC) across various attack scenarios and data distributions. These findings highlight the potential of PenTiDef as a scalable and secure framework for deploying DFL-based IDS in adversarial environments. By leveraging privacy protection, malicious behavior detection in hidden data, and working without a central server, it provides a useful security solution against real-world attacks from untrust participants.", "published": "2026-02-20T03:58:48Z", "updated": "2026-02-20T03:58:48Z", "authors": ["Phan The Duy", "Nghi Hoang Khoa", "Nguyen Tran Anh Quan", "Luong Ha Tien", "Ngo Duc Hoang Son", "Van-Hau Pham"], "pdf_url": "https://arxiv.org/pdf/2602.17973v1"}
