{"id": "http://arxiv.org/abs/2602.07871v1", "title": "HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid", "summary": "Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.", "published": "2026-02-08T08:57:05Z", "updated": "2026-02-08T08:57:05Z", "authors": ["Xiang Li", "Siyu Lu", "Sarro Federica", "Claire Le Goues", "He Ye"], "pdf_url": "https://arxiv.org/pdf/2602.07871v1"}
{"id": "http://arxiv.org/abs/2602.07821v1", "title": "Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution", "summary": "In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.", "published": "2026-02-08T04:57:57Z", "updated": "2026-02-08T04:57:57Z", "authors": ["Shinobu Saito"], "pdf_url": "https://arxiv.org/pdf/2602.07821v1"}
{"id": "http://arxiv.org/abs/2602.05721v2", "title": "A Dual-Loop Agent Framework for Automated Vulnerability Reproduction", "summary": "Automated vulnerability reproduction from CVE descriptions requires generating executable Proof-of-Concept (PoC) exploits and validating them in target environments. This process is critical in software security research and practice, yet remains time-consuming and demands specialized expertise when performed manually. While LLM agents show promise for automating this task, existing approaches often conflate exploring attack directions with fixing implementation details, which leads to unproductive debugging loops when reproduction fails. To address this, we propose CVE2PoC, an LLM-based dual-loop agent framework following a plan-execute-evaluate paradigm. The Strategic Planner analyzes vulnerability semantics and target code to produce structured attack plans. The Tactical Executor generates PoC code and validates it through progressive verification. The Adaptive Refiner evaluates execution results and routes failures to different loops: the Tactical Loop for code-level refinement, while the Strategic Loop for attack strategy replanning. This dual-loop design enables the framework to escape ineffective debugging by matching remediation to failure type. Evaluation on two benchmarks covering 617 real-world vulnerabilities demonstrates that CVE2PoC achieves 82.9% and 54.3% reproduction success rates on SecBench.js and PatchEval, respectively, outperforming the best baseline by 11.3% and 20.4%. Human evaluation confirms that generated PoCs achieve comparable code quality to human-written exploits in readability and reusability.", "published": "2026-02-05T14:47:48Z", "updated": "2026-02-08T04:40:30Z", "authors": ["Bin Liu", "Yanjie Zhao", "Zhenpeng Chen", "Guoai Xu", "Haoyu Wang"], "pdf_url": "https://arxiv.org/pdf/2602.05721v2"}
{"id": "http://arxiv.org/abs/2602.07783v1", "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards", "summary": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.", "published": "2026-02-08T02:57:47Z", "updated": "2026-02-08T02:57:47Z", "authors": ["Zejun Zhang", "Yixin Gan", "Zhenchang Xing", "Tian Zhang", "Yi Li", "Xiwei Xu", "Qinghua Lu", "Liming Zhu"], "pdf_url": "https://arxiv.org/pdf/2602.07783v1"}
{"id": "http://arxiv.org/abs/2601.23254v2", "title": "GrepRAG: An Empirical Study and Optimization of Grep-Like Retrieval for Code Completion", "summary": "Repository-level code completion remains challenging for large language models (LLMs) due to cross-file dependencies and limited context windows. Prior work addresses this challenge using Retrieval-Augmented Generation (RAG) frameworks based on semantic indexing or structure-aware graph analysis, but these approaches incur substantial computational overhead for index construction and maintenance. Motivated by common developer workflows that rely on lightweight search utilities (e.g., ripgrep), we revisit a fundamental yet underexplored question: how far can simple, index-free lexical retrieval support repository-level code completion before more complex retrieval mechanisms become necessary? To answer this question, we systematically investigate lightweight, index-free, intent-aware lexical retrieval through extensive empirical analysis. We first introduce Naive GrepRAG, a baseline framework in which LLMs autonomously generate ripgrep commands to retrieve relevant context. Despite its simplicity, Naive GrepRAG achieves performance comparable to sophisticated graph-based baselines. Further analysis shows that its effectiveness stems from retrieving lexically precise code fragments that are spatially closer to the completion site. We also identify key limitations of lexical retrieval, including sensitivity to noisy matches from high-frequency ambiguous keywords and context fragmentation caused by rigid truncation boundaries. To address these issues, we propose GrepRAG, which augments lexical retrieval with a lightweight post-processing pipeline featuring identifier-weighted re-ranking and structure-aware deduplication. Extensive evaluation on CrossCodeEval and RepoEval-Updated demonstrates that GrepRAG consistently outperforms state-of-the-art (SOTA) methods, achieving 7.04-15.58 percent relative improvement in code exact match (EM) over the best baseline on CrossCodeEval.", "published": "2026-01-30T18:22:15Z", "updated": "2026-02-08T02:55:24Z", "authors": ["Baoyi Wang", "Xingliang Wang", "Guochang Li", "Chen Zhi", "Junxiao Han", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "pdf_url": "https://arxiv.org/pdf/2601.23254v2"}
